{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 2: GeForce GTX TITAN X (CNMeM is disabled, cuDNN 4007)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Input\n",
    "from keras.layers import Reshape\n",
    "from keras.models import Model\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import UpSampling2D\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.layers.core import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import argparse\n",
    "import math\n",
    "from keras.applications import VGG16, vgg16\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gram_matrix(x):\n",
    "    assert K.ndim(x) == 3\n",
    "    features = K.batch_flatten(K.permute_dimensions(x, (0, 1, 2)))\n",
    "    gram = K.dot(features, K.transpose(features))\n",
    "    return gram\n",
    "\n",
    "# the \"style loss\" is designed to maintain\n",
    "# the style of the reference image in the generated image.\n",
    "# It is based on the gram matrices (which capture style) of\n",
    "# feature maps from the style reference image\n",
    "# and from the generated image\n",
    "\n",
    "def style_loss(style, combination):\n",
    "    assert K.ndim(style) == 3\n",
    "    assert K.ndim(combination) == 3\n",
    "    S = gram_matrix(style)\n",
    "    C = gram_matrix(combination)\n",
    "    channels = 3\n",
    "    size = img_nrows * img_ncols\n",
    "    sLoss = K.sum(K.square(S - C)) / (4. * (channels ** 2) * (size ** 2))\n",
    "    return sLoss\n",
    "\n",
    "def content_loss(base, combination):\n",
    "    return K.sum(K.square(combination - base))\n",
    "\n",
    "\n",
    "def total_variation_loss(x):\n",
    "    assert K.ndim(x) == 4\n",
    "    a = K.square(x[:, :, :img_nrows - 1, :img_ncols - 1] - x[:, :, 1:, :img_ncols - 1])\n",
    "    b = K.square(x[:, :, :img_nrows - 1, :img_ncols - 1] - x[:, :, :img_nrows - 1, 1:])\n",
    "    return K.sum(K.pow(a + b, 1.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_variation_weight = 1.0\n",
    "style_weight = 100.0\n",
    "content_weight = 0.025\n",
    "\n",
    "img_nrows = 400\n",
    "img_ncols = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# style_loss\n",
    "def get_loss(y_true, y_pred):\n",
    "    loss = style_loss(y_true[0, :, :, :], y_pred[0, :, :, :])\n",
    "    print \"loss\", K.shape(loss), loss\n",
    "    return style_weight*loss\n",
    "\n",
    "def c_loss(y_true, y_pred):\n",
    "    loss = content_loss(y_true[0, :, :, :], y_pred[0, :, :, :])\n",
    "    print \"c_loss\", K.shape(loss), loss\n",
    "#     loss += total_variation_loss(y_pred)\n",
    "    return content_weight*loss\n",
    "\n",
    "def var_loss(y_true, y_pred):\n",
    "    loss = total_variation_weight*total_variation_loss(y_pred)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Combine generative layer with VGG layer\n",
    "inputs = Input(shape=(3, 400, 400))\n",
    "\n",
    "vggTmp = vgg16.VGG16(input_tensor = inputs, weights='imagenet', include_top=False)\n",
    "for layer in vggTmp.layers:\n",
    "    layer.trainable=False\n",
    "\n",
    "x1 = vggTmp.layers[12].output\n",
    "# 512, 28, 28\n",
    "\n",
    "# Joining layer\n",
    "x = Convolution2D(64, 3, 3, border_mode = 'same', activation = 'relu', init = 'glorot_normal')(x1)\n",
    "x = MaxPooling2D(pool_size = (2, 2))(x)\n",
    "\n",
    "x = UpSampling2D(size = (2, 2))(x) #shape is (16, 14, 14)\n",
    "x = Convolution2D(32, 5, 5, border_mode = 'same', activation = 'relu', init = 'glorot_normal')(x)\n",
    "\n",
    "x = UpSampling2D(size = (4, 4))(x) #shape is (16, 14, 14)\n",
    "x = Convolution2D(32, 5, 5, border_mode = 'same', activation = 'relu', init = 'glorot_normal')(x)\n",
    "\n",
    "x = UpSampling2D(size = (8, 8))(x) #shape is (16, 14, 14)\n",
    "x = Convolution2D(32, 5, 5, border_mode = 'same', activation = 'relu', init = 'glorot_normal')(x)\n",
    "\n",
    "\n",
    "x = UpSampling2D(size = (16, 16))(x) # 28, 28 -> 224, 224\n",
    "out = Convolution2D(3, 5, 5, border_mode = 'same', activation = 'sigmoid', init = 'glorot_normal')(x)\n",
    "\n",
    "\n",
    "generative_model = Model(input = inputs, output = out)\n",
    "\n",
    "# VGG model\n",
    "vgg_model = VGG16(weights = 'imagenet', include_top = False)\n",
    "for layer in vgg_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "fl = ['block1_conv1', 'block2_conv1','block3_conv1', 'block4_conv1', 'block5_conv1', 'block4_conv2']\n",
    "ot = dict([(layer.name, layer.output) for layer in vgg_model.layers])\n",
    "outputs = [vgg_model.input, ot[fl[5]], ot[fl[0]], ot[fl[1]], ot[fl[2]], ot[fl[3]], ot[fl[4]]]\n",
    "# Discriminative model\n",
    "disc_model = Model(input = vgg_model.input, output = outputs)\n",
    "vgg_out = disc_model(out)\n",
    "\n",
    "# Final model\n",
    "fin_model = Model(input = inputs, output = vgg_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c_loss Shape.0 Sum{acc_dtype=float64}.0\n",
      "loss Shape.0 Elemwise{true_div,no_inplace}.0\n",
      "loss Shape.0 Elemwise{true_div,no_inplace}.0\n",
      "loss Shape.0 Elemwise{true_div,no_inplace}.0\n",
      "loss Shape.0 Elemwise{true_div,no_inplace}.0\n",
      "loss Shape.0 Elemwise{true_div,no_inplace}.0\n"
     ]
    }
   ],
   "source": [
    "fin_model.compile(loss = [var_loss, c_loss, get_loss, get_loss, get_loss, get_loss, get_loss], optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_style_features(filename):\n",
    "    jpgfile = Image.open(filename)\n",
    "    inp = np.array(jpgfile.getdata())\n",
    "    inp = np.array(jpgfile.getdata())\n",
    "    inp = inp.swapaxes(0, 1)\n",
    "    inp = np.reshape(inp, (1, 3, 400, 400))\n",
    "    styleY = disc_model.predict([inp/256.0])\n",
    "    return styleY\n",
    "\n",
    "def get_origin_features(filename):\n",
    "    jpgfile = Image.open(filename)\n",
    "    inp = np.array(jpgfile.getdata())\n",
    "    inp = inp.swapaxes(0, 1)\n",
    "    inp = np.reshape(inp, (1, 3, 400, 400))\n",
    "    contentY = disc_model.predict([inp/256.0])\n",
    "    return contentY\n",
    "\n",
    "def get_train_features(filename):\n",
    "    jpgfile = Image.open(filename)\n",
    "    inp = np.array(jpgfile.getdata())\n",
    "    inp = inp.swapaxes(0, 1)\n",
    "    trainX = np.reshape(inp, (1, 3, 400, 400))\n",
    "#     trainX2 = np.reshape(trainX, (1, np.product(trainX.shape)))\n",
    "    trainX3 = trainX/256.0\n",
    "    return trainX3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "styleY = get_style_features('starry400.jpg') \n",
    "contentY = get_origin_features('ucsd400.jpg')\n",
    "trainX3 = get_train_features('ucsd400.jpg')\n",
    "styleY[1] = contentY[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken 17.1929769516\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "hist = fin_model.fit(trainX3, styleY, nb_epoch = 50, verbose = 0)\n",
    "end = time.time()\n",
    "print \"Time taken\", end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "def loadCaltechImages(path, n_samples):\n",
    "    catList = listdir(path)\n",
    "    \n",
    "    data = []\n",
    "    for cat in catList[0:100]:\n",
    "        deepPath = path + cat + \"/\"\n",
    "        imageList = listdir(deepPath)\n",
    "        \n",
    "        for image in imageList[:n_samples]:\n",
    "            img = load_img(deepPath+image, target_size = (400, 400))\n",
    "            data.append(img)\n",
    "            \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "path = \"/mnt/cube/VGG_/256_ObjectCategories/\"    \n",
    "n_samples = 5\n",
    "imageList = loadCaltechImages(path, n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_style_features(filename):\n",
    "    jpgfile = Image.open(filename)\n",
    "    inp = np.array(jpgfile.getdata())\n",
    "    inp = np.array(jpgfile.getdata())\n",
    "    inp = inp.swapaxes(0, 1)\n",
    "    inp = np.reshape(inp, (1, 3, 400, 400))\n",
    "    styleY = disc_model.predict([inp/256.0])\n",
    "    return styleY\n",
    "\n",
    "def get_origin_features(inp):\n",
    "    inp = inp.swapaxes(0, 2).swapaxes(1, 2)\n",
    "    inp = np.reshape(inp, (1, 3, 400, 400))\n",
    "    contentY = disc_model.predict([inp/256.0])\n",
    "    return contentY\n",
    "\n",
    "def get_train_features(inp):\n",
    "    inp = inp.swapaxes(0, 2).swapaxes(1, 2)\n",
    "    trainX = np.reshape(inp, (1, 3, 400, 400))\n",
    "    trainX3 = trainX/256.0\n",
    "    return trainX3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "styleY = get_style_features('starry400.jpg') \n",
    "for image in imageList:\n",
    "    contentY = get_origin_features(np.asarray(image))\n",
    "    trainX = get_train_features(np.asarray(image))\n",
    "    styleY[1] = contentY[1]\n",
    "    X.append(trainX)\n",
    "    Y.append(styleY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Error allocating 83886080000 bytes of device memory (out of memory).\nApply node that caused the error: GpuAlloc(GpuDimShuffle{0,1,2,3,x}.0, Elemwise{switch,no_inplace}.0, TensorConstant{32}, Elemwise{Composite{Switch(EQ(i0, i1), i2, i0)}}.0, Elemwise{switch,no_inplace}.0, TensorConstant{16})\nToposort index: 767\nInputs types: [CudaNdarrayType(float32, (False, False, False, False, True)), TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int8, scalar)]\nInputs shapes: [(1, 32, 25600, 1600, 1), (), (), (), (), ()]\nInputs strides: [(0, 40960000, 1600, 1, 0), (), (), (), (), ()]\nInputs values: ['not shown', array(1), array(32), array(25600), array(1600), array(16, dtype=int8)]\nOutputs clients: [[GpuReshape{4}(GpuAlloc.0, MakeVector{dtype='int64'}.0)]]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-10ddc5cd5588>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mfin_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch)\u001b[0m\n\u001b[0;32m   1194\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1195\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1196\u001b[1;33m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1198\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[0;32m    889\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 891\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    957\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 959\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    960\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    961\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    869\u001b[0m                     \u001b[0mnode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m                     \u001b[0mthunk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mthunk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 871\u001b[1;33m                     storage_map=getattr(self.fn, 'storage_map', None))\n\u001b[0m\u001b[0;32m    872\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m                 \u001b[1;31m# old-style linkers raise their own exceptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/gof/link.pyc\u001b[0m in \u001b[0;36mraise_with_op\u001b[1;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[0;32m    312\u001b[0m         \u001b[1;31m# extra long error message in that case.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m     \u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Error allocating 83886080000 bytes of device memory (out of memory).\nApply node that caused the error: GpuAlloc(GpuDimShuffle{0,1,2,3,x}.0, Elemwise{switch,no_inplace}.0, TensorConstant{32}, Elemwise{Composite{Switch(EQ(i0, i1), i2, i0)}}.0, Elemwise{switch,no_inplace}.0, TensorConstant{16})\nToposort index: 767\nInputs types: [CudaNdarrayType(float32, (False, False, False, False, True)), TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int8, scalar)]\nInputs shapes: [(1, 32, 25600, 1600, 1), (), (), (), (), ()]\nInputs strides: [(0, 40960000, 1600, 1, 0), (), (), (), (), ()]\nInputs values: ['not shown', array(1), array(32), array(25600), array(1600), array(16, dtype=int8)]\nOutputs clients: [[GpuReshape{4}(GpuAlloc.0, MakeVector{dtype='int64'}.0)]]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node."
     ]
    }
   ],
   "source": [
    "nb_epochs = 10\n",
    "batch_size = 100\n",
    "n_train = len(X)\n",
    "for i in range(nb_epochs):\n",
    "    print i\n",
    "    batch = np.random.choice(n_train, 100)\n",
    "    for item in batch:\n",
    "        x = X[i]\n",
    "        y = Y[i]\n",
    "        fin_model.fit(x, y, nb_epoch = 1, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
